Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
1. INTRODUCCIÃ“N
La capacidad de aprender es una de las funciones mentales mÃ¡s importantes de los seres vivos
ya que les permite adaptarse a las necesidades del entorno con el objetivo de aumentar sus
posibilidades de supervivencia. Mediante el proceso de aprendizaje los seres vivos son capaces
de modificar, adaptar y/o adquirir habilidades, destrezas, conocimientos y/o comportamientos
mediante la interacciÃ³n con el entorno que les rodea. Este proceso puede ser incluso mucho mÃ¡s
complejo desde la perspectiva de los seres humanos donde el proceso de aprendizaje no se
limita sÃ³lo al entorno y a sus interacciones con Ã©l, sino que tambiÃ©n influyen ciertos factores
sociales relacionados con valores y principios morales que influyen de manera significativa sobre
las diferentes habilidades, destrezas, conocimientos y conductas que somos capaces de
aprender. Este tipo de diferencias (sesgo) se pueden apreciar significativamente cuando
comparamos dos individuos con las mismas capacidades cognitivas que han crecido en
diferentes zonas geogrÃ¡ficas del planeta donde existen significativas diferencias en la forma de
vida. Probablemente ambos individuos se comportarÃ¡n de forma diferente ante estÃ­mulos
similares ya que han creado modelos de comportamientos diferentes en base a la informaciÃ³n
que han recibido.
Esta poderosa capacidad para construir modelos de comportamiento en base a la extracciÃ³n y
manipulaciÃ³n la informaciÃ³n del entorno hicieron que los investigadores comenzaran a imitar el
proceso de aprendizaje humano con el fin de aumentar las capacidades de los diferentes
algoritmos de Inteligencia Artificial los cuales estaban limitados por el conocimiento experto que
se les introducÃ­a para poder razonar y por los comportamientos (acciones, operaciones, etc.) que
eran definidos por los diseÃ±adores de los sistemas. Es decir, los diferentes algoritmos de
Inteligencia Artificial no eran capaces de adaptarse a nuevas situaciones si estÃ¡n no habÃ­an sido
previstas en los modelos que eran utilizados para producir el proceso de razonamiento. Este
nuevo Ã¡rea conocimiento perteneciente a la Inteligencia Artificial comenzÃ³ a denominarse
â€œAprendizaje AutomÃ¡ticoâ€ (Machine Learning, ML, en sus siglas en inglÃ©s) debido a que su
objetivo era construir modelos de comportamiento mediante el aprendizaje en base a la
informaciÃ³n disponible del entorno. Dependiendo de cÃ³mo se produce el proceso de construcciÃ³n
de los modelos de aprendizaje podemos diferenciar entre diferentes modos de aprendizaje:
â–ª
Aprendizaje inductivo: Este tipo de modo de aprendizaje consiste en construir modelos a
partir de un proceso de generalizaciÃ³n mediante ejemplos simples. Es decir, permite
identificar un conjunto de patrones comunes que permitan definir ciertas caracterÃ­sticas
de los diferentes ejemplos utilizados en el proceso de aprendizaje. Este proceso se basa

4Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
en el razonamiento inductivo [11] mediante el cual los humanos extraemos conclusiones
generales de forma independiente a travÃ©s de un proceso de anÃ¡lisis de la informaciÃ³n
disponible con el fin de resolver un determinado problema. El conocimiento utilizado
siempre se considera nuevo y puede modificar o invalidar el modelo previamente
aprendido.
â–ª
Aprendizaje analÃ­tico o deductivo: Este tipo de modo de aprendizaje consiste en construir
modelos a partir de un proceso deductivo mediante la identificaciÃ³n de una descripciÃ³n
general a partir de un conjunto de ejemplos los cuales son explicados de forma especÃ­fica
y completa. Este proceso se basa en el razonamiento deductivo [12] mediante el cual los
humanos aprendemos comunmente en el colegio donde se presentan una serie de reglas
o leyes las cuales son demostradas en base a una serie de ejemplos que explican de
forma el funcionamiento de las diferentes leyes. El nuevo conocimiento no invalida el
conocimiento previo sÃ³lo lo completa o refuerza.
â–ª
Aprendizaje analÃ³gico: Este tipo de modo de aprendizaje consiste en construir modelos
que permiten generar soluciones a problemas nuevos mediante la bÃºsqueda de
similitudes con problemas previamente resueltos de forma que la soluciÃ³n de los
problemas similares es adaptada a las particularidades del nuevo problema con el fin de
aprender una soluciÃ³n [13]. Este tipo de concepto de aprendizaje es el aplicado para
diseÃ±ar los sistemas de razonamiento basados en caso descritos en el tema anterior.
Algunos investigadores no lo consideran como un proceso total de aprendizaje ya que
depende de una fase de adaptaciÃ³n de puede producir muchÃ­simas variaciones en la
soluciÃ³n final.
â–ª
Aprendizaje conexionista: Este tipo de modo de aprendizaje consiste en construir
modelos basados en las conexiones de entidades sencillas con el fin de aprender ciertos
conceptos en base a como se configuran estas conexiones. Este tipo de procesos de
aprendizaje se han intentado aplicar en el proceso de construcciÃ³n de redes de neuronas
con el fin de crear sistemas dinÃ¡micos que adaptan sus conexiones.
â–ª
Aprendizaje conductista: Este tipo de modo de aprendizaje, basado en la psicologÃ­a
conductista, consiste en construir modelos en base a la observaciÃ³n y anÃ¡lisis de las
reacciones (conductas) aplicadas en el entorno como respuesta a un determinado
estÃ­mulo que puede suponer una determinada recompensa.
La apariciÃ³n del Aprendizaje AutomÃ¡tico[10] supuso un cambio radical en la forma en la que se
estaba abordando el proceso de creaciÃ³n de sistemas basados en Inteligencia Artificial, ya que
5
Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
a partir de este momento no se intentaban construir algoritmos que fuera capaces de resolver
problemas de forma automÃ¡tica, sino que se intentan construir algoritmos que fueran capaces
de aprender modelos en base a la informaciÃ³n que tienen disponible. Esto supuso la apariciÃ³n
de diferentes tipos de familias de mÃ©todos que abordaban diferentes facetas del proceso de
aprendizaje comenzando con las primeras versiones del perceptrÃ³n [2] [3] hasta los complejos
modelos construidos mediante la utilizaciÃ³n del Aprendizaje Profundo (Deep Learning) en base
a millones de datos y complejas estructuras basadas en redes de neuronas [4]. En los Ãºltimos
aÃ±os la apariciÃ³n de diferentes Frameworks [14] [15], que facilitan el procesamiento y generaciÃ³n
de modelos de aprendizaje, ha supuesto que las empresas hayan centrado sus esfuerzos en
utilizar este tipo de tÃ©cnicas para ofrecer nuevos servicios y funcionalidades en un amplio grupo
de Ã¡reas como, por ejemplo:
â–ª
Movilidad: IdentificaciÃ³n de rutas por carretera mÃ¡s eficientes que minimicen el nÃºmero
de embotellamientos en las principales arterias de la ciudad disminuyendo el tiempo,
consumo y/o contaminaciÃ³n.
â–ª
Sistemas de producciÃ³n: PredicciÃ³n de errores de funcionamiento en sistema de
producciÃ³n supervisado o semisupervisado.
â–ª
Finanzas: PrevenciÃ³n de fraudes bancarÃ­as, lavado de dinero y personalizar la oferta de
productos basados en datos del usuario y del mercado con el fin de conocer quÃ© tipo de
productos se adaptan mejor a un determinado usuario.
â–ª
Agricultura: IdentificaciÃ³n de las mejores Ã¡reas de cultivo para cada tipo de producto,
identificaciÃ³n de fechas de recogida de los productos en el momento Ã³ptimo de
maduraciÃ³n, asÃ­ como la identificaciÃ³n de los posibles problemas en el proceso de
crecimiento, identificaciÃ³n de enfermedades (visiÃ³n artificial).
â–ª
EnergÃ­a: PredicciÃ³n de errores e identificaciÃ³n de zonas en la cual es necesario realizar
algÃºn tipo de mantenimiento preventivo. IdentificaciÃ³n de los cambios en el coste de la
energÃ­a con el fin de recomendar a los clientes cuando aumentar o disminuir su consumo
con el fin de minimizar los costes.
â–ª
Salud: Diagnostico y detecciÃ³n de enfermedades mediante el anÃ¡lisis de la informaciÃ³n
del usuario. AsÃ­ como el uso de sistema de visiÃ³n artificial para la detecciÃ³n de tumores.
â–ª
FarmacÃ©utico: Optimizar de los diferentes estudios clÃ­nicos realizados mediante la
selecciÃ³n automÃ¡tica de pacientes en base a sus caracterÃ­sticas.
â–ª
Medios de comunicaciÃ³n: PersonalizaciÃ³n de publicidad y recomendaciones mediante la
utilizaciÃ³n de datos multimodales referentes a los usuarios.

6Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
â–ª
LogÃ­stica: OptimizaciÃ³n en tiempo real de precios de los productos, horarios de apertura,
cantidad de producto almacenado en base a los comportamientos previos de los clientes
en situaciones o fechas similares.
â–ª
Sector pÃºblico y social: OptimizaciÃ³n del proceso de asignaciÃ³n de recursos para el
desarrollo urbano con el fin de mejorar la calidad de vida de los usuarios con el fin de
minimizar la delincuencia, adaptar los servicios de limpieza a la cantidad de personas en
un Ã¡rea. Por ejemplo, aumentar los efectivos de limpieza en ciertos dÃ­as del aÃ±o debido
a la existencia de eventos o de una mayor afluencia de turÃ­sticas.
â–ª
Viajes y hotelerÃ­a: IdentificaciÃ³n rutas mÃ¡s eficientes con el fin optimizar itinerario de
vuelos, vehÃ­culos de transporte de productos perecederos o para la realizaciÃ³n de
entregas mediante la utilizaciÃ³n de transporte local por carretera.
2. FUNDAMENTOS BÃSICOS DEL APRENDIZAJE AUTOMÃTICO
En esta secciÃ³n se presentan los fundamentos bÃ¡sicos del Aprendizaje AutomÃ¡tico. Para ello se
presentarÃ¡ una descripciÃ³n teÃ³rica del concepto del Aprendizaje AutomÃ¡tico basada en el
concepto de Aprendizaje en humanos, se describirÃ¡n los diferentes elementos bÃ¡sicos
necesarios para entender cÃ³mo funcionan el proceso de generaciÃ³n de un modelo de
aprendizaje, a continuaciÃ³n, se describirÃ¡n aquellos aspectos bÃ¡sicos referentes a los modelos
que podemos aprender y por Ãºltimo se describirÃ¡n las diferentes tÃ©cnicas agrupadas por tipo o
familia.
2.1 El proceso de Aprendizaje AutomÃ¡tico
Desde la perspectiva de una mÃ¡quina el aprendizaje automÃ¡tico puede definirse como el proceso
de adquisiciÃ³n de conocimiento de manera automÃ¡tica mediante la utilizaciÃ³n de ejemplos de
entrenamiento que define las caracterÃ­sticas del concepto que se desea aprender. Este proceso
de adquisiciÃ³n de conocimiento (aprendizaje) puede ser visto como un proceso de generaciÃ³n
de cambios en el sistema que aprende (estudiante) los cuales son definidos por la informaciÃ³n
obtenida del entorno (ejemplos de entrada). Esta informaciÃ³n puede ser definida mediante otro
sistema que nos enseÃ±a (profesor) que realiza una identificaciÃ³n de la informaciÃ³n (datos
etiquetados) o bien mediante la extracciÃ³n de informaciÃ³n en bruto que no estÃ¡ identificada (datos
no etiquetados). Estos implican que los sistemas de aprendizaje deben ser capaces de trabajar
con un rango muy amplio de informaciÃ³n de entrada, que pueden incluir datos incompletos,
inciertos, ruido, inconsistencias, etc., con el fin de construir modelos imperfectos los cuales
7
Â© StructuraliaInteligencia artificial â€“ Aprendizaje automÃ¡tico I
pueden ser analizados con el fin de conocer su grado de existo y adecuaciÃ³n al problema.
Dependiendo de cÃ³mo se utilice la informaciÃ³n de entrada y salida durante el proceso de
aprendizaje se pueden diferenciar entre cuatro grandes grupos o familias de tÃ©cnicas:
aprendizaje supervisado, aprendizaje no supervisado, aprendizaje semisupervisado y el
aprendizaje por refuerzo. Cada una de estas familias serÃ¡n descritas de forma detallada a lo
largo de este tema y el siguiente.
2.2 Conceptos bÃ¡sicos
Para poder describir de forma correcta cÃ³mo funcionan las diferentes tÃ©cnicas de Aprendizaje
AutomÃ¡tico es necesario introducir algunos conceptos bÃ¡sicos. En la Figura 1 se presenta el
proceso de aprendizaje de un algoritmo cualesquiera de tipo supervisado o semisupervisado.
Cada uno de los diferentes elementos de la figura son descritos a continuaciÃ³n con el fin de
describir en detalle cada uno de los bÃ¡sicos utilizados en proceso de aprendizaje.
Figura 1: DescripciÃ³n bÃ¡sica del proceso de aprendizaje de un algoritmo de tipo supervisado o semisupervisado.
â–ª
Atributo: Los atributos, variables de entrada o componentes son las unidades bÃ¡sicas e
indivisibles de informaciÃ³n utilizada para representar algÃºn tipo de conocimiento. Este tipo
de informaciÃ³n representa una caracterÃ­stica bÃ¡sica que intenta describir algÃºn tipo de
Â© Structuralia
8Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
propiedad sobre los datos (color, tamaÃ±o, distancia, etc). Los atributos suelen clasificarse
en dos categorÃ­as en base a los valores que pueden tomar:
o
Continuos: Son aquellos atributos que toman un valor fijo dentro de un intervalo no
finito perfectamente acotado donde dados dos valores observables siempre existen
un tercer valor intermedio que podrÃ­a tomar el atributo continuo. Por ejemplo, la
temperatura de una determinada habitaciÃ³n medida en grados centÃ­grados puede
tomar valores de tipo real en un rango comprendido entre -50Âº y 50Âº centÃ­grados.
o
Discretos: Son aquellos atributos que toman su valor entre los elementos que forman
un conjunto finito. Por ejemplo, los posibles colores de pintura utilizados para pintar
un vehÃ­culo.
â–ª
Instancia: Una instancia es la estructura de informaciÃ³n bÃ¡sica utilizada para representar
cada uno de los ejemplos que forma parte de los conjuntos de datos que serÃ¡n utilizados
en el proceso de aprendizaje. Cada instancia, a su vez, estÃ¡ compuesta por un conjunto
finito de atributos que la describen. La instancia de un mismo conjunto tiene que estar
formadas por el mismo tipo de atributos. La Tabla 1 muestra un conjunto de instancia
referentes a la climatologÃ­a del entorno con el fin de saber si se puede o no jugar un
partido de tenis. Cada una de las instancias estÃ¡ compuesta por atributos de tipo continuo
(Humedad) y discreto (Cielo, Temperatura y Viento).
IDCieloTemperaturaHumedadVientoJugar (Etiqueta)
1SoleadoAlta65,28LeveSÃ­
2NubladoAlta60,45LeveSÃ­
3LluviaNormal68,12IntensaNo
Tabla 1 - Ejemplo de un conjunto de instancia con diferente tipo de atributos
â–ª
Objetivo (clase): Es un atributo especial utilizado para realizar la predicciÃ³n, es decir es
el objetivo de la predicciÃ³n. Por ejemplo, la probabilidad de que un paciente tenga una
determinada enfermedad o el precio al que se venderÃ¡ una vivienda.
â–ª
Conjunto de datos: Es el conjunto de instancias que son utilizadas para el proceso de
aprendizaje. La manera en la que este conjunto de informaciÃ³n es utilizado depende del
9
Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
tipo de tÃ©cnica que estemos utilizando. Es decir, la informaciÃ³n puede haber sido recogida
previamente y almacenada en ficheros, u otro tipo de formato de almacenamiento, que
serÃ¡n utilizados para construir en modelos o puede ser recogida en tiempo real durante
el proceso de entrenamiento.
â–ª
Modelo: Es el resultado del proceso de aprendizaje. De manera formal se puede definir
como el conjunto de reglas o patrones inferidos a partir del conjunto de entrenamiento
utilizado para construirlo.
â–ª
Algoritmo: Es el mecanismo mediante el cual se produce el proceso de aprendizaje. Este
algoritmo funciona de manera diferentes dependiendo del tipo de salida y de entrada que
queremos utilizar para construir el modelo. Cada uno de los diferentes algoritmos de
aprendizaje supervisado, no supervisado y semisupervisado puede definirse como uno
de los tres tipos de tÃ©cnicas.
Figura 2: Ejemplo de la distribuciÃ³n espacial de un conjunto de instancias
en base al funcionamiento de tres tipos de algoritmos
o
ClasificaciÃ³n: Los algoritmos de clasificaciÃ³n son aquellos que tratan de predecir una
salida de tipo discreto que consiste en un atributo de tipo discreto (clases) a partir de
un conjunto de datos que pueden estar o no etiquetados (Imagen izquierda Figura 2).
Las diferentes instancias de entrada (entrenamiento y test) se encuentran ordenadas
en categorÃ­as o clases. Cada una de estas clases son las etiquetas que han sido
asignadas a los datos. Se suelen diferenciar dos tipos de algoritmos: clasificaciÃ³n
binaria donde sÃ³lo es necesario predecir dos clases objetivo (Si o No) y clasificaciÃ³n
multiclase donde se debe predecir mÃ¡s de 2 clases objetivo.
o
RegresiÃ³n: Los algoritmos de regresiÃ³n o estimaciÃ³n son aquellos que tratan de
predecir una salida de tipo continuo que consiste en un valor numÃ©rico (nÃºmero real)

10Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
a partir de un conjunto de datos etiquetados (Imagen central Figura 2). Cada una de
las diferentes instancias de entrada (entrenamiento y test) tiene un atributo de â€œsalidaâ€
de tipo continuo.
o
Agrupamiento: Los algoritmos de agrupamiento (clustering) son aquellos que tratan
de predecir una salida de tipo discreto a partir de un conjunto de datos que pueden
estar o no etiquetados (Imagen derecha Figura 2). Es decir, estos algoritmos son
capaces de agrupar los elementos en base a las similitudes entre sus atributos en un
conjunto determinado de grupos, cuyo nÃºmero debe ser incluido como una entrada
mÃ¡s del algoritmo.
2.3 El modelo de aprendizaje
El proceso descrito en la secciÃ³n anterior nos permite conocer cual son los componentes bÃ¡sicos
para poder generar un modelo de aprendizaje, pero no es tan sencillo. En primer lugar, este
proceso difiere dependiendo de cada una de las diferentes familias de mÃ©todos. Los algoritmos
de aprendizaje no supervisado no suelen incluir una fase de test ya no la informaciÃ³n utilizada
para el proceso de aprendizaje no estÃ¡ etiquetada y los algoritmos de aprendizaje por refuerzo
modelan la informaciÃ³n mediante la utilizaciÃ³n de estados, acciones y recompensas que de un
punto de vista muy general pueden ser similares cambian por completo el proceso de
aprendizaje. Los pares estado acciÃ³n pueden ser visto como instancias y el refuerzo como algo
parecido a la clase. Todo esto serÃ¡ descrito de forma detallada en el siguiente tema de este
curso.
Con respecto al proceso de aprendizaje en general es necesario introducir algunos conceptos
bÃ¡sicos referentes al modelo y al tratamiento de la informaciÃ³n utilizada para construirlo.
â–ª
DiscretizaciÃ³n: Es el proceso mediante el cual una variable de tipo continuo es
transformada en una variable de tipo discreto. Este proceso normalmente se realiza
mediante la utilizaciÃ³n de los valores disponibles en el conjunto de entrenamiento, en
base a sus valores el conjunto es dividido en rangos donde cada uno se corresponderÃ¡
con un valor discreto de la nueva variable. Esta divisiÃ³n se realiza comÃºnmente de
manera manual lo cual hace que se introduzcan sesgos en el proceso de aprendizaje.
Aunque existen tÃ©cnicas que realizan divisiones automÃ¡ticas del conjunto en rangos de
tamaÃ±o similar.
11
Â© StructuraliaInteligencia artificial â€“ Aprendizaje automÃ¡tico I
â–ª
NormalizaciÃ³n: Es el proceso de ajuste de los diferentes valores de un atributo con el fin
de disminuir importantes diferentes entre los valores o representarlos en otro tipo de
escala que permita analizar de forma mÃ¡s efectiva su efecto sobre el resto de los
atributos o su significado. Lo mÃ¡s comÃºn es realizar una normalizaciÃ³n a valores entre 0
y 1.
â–ª
Valor atÃ­pico: Los valores atÃ­picos o outlets son valores que pueden tomar los atributos
muy distantes con respecto al resto de valores que poseen las otras instancias de los
conjuntos (entrenamiento y test) empleados en el proceso de aprendizaje. Estos cambios
tan importantes en los valores de un atributo pueden significar que se ha producido un
error en mediciÃ³n o que se ha detectado un caso inusual que no es comÃºn que se
reproduzca. Normalmente este tipo de valores son eliminados de los conjuntos de
entrenamiento y/o test debido a que pueden afectar de manera significativa al proceso
de generaciÃ³n del modelo. Aunque este proceso de eliminaciÃ³n puede ser bastante
complicado si los conjuntos utilizados en el proceso de aprendizaje son muy grandes,
por lo que algunas tÃ©cnicas incluyen procesos para detecciÃ³n de valores atÃ­picos con el
fin de eliminarlos y/o tratarlos de manera diferente durante el proceso de aprendizaje.
Algunos de los mÃ©todos mÃ¡s utilizados para la detecciÃ³n de estos valores son: (1)
MÃ©todos monovariables que buscan valores atÃ­picos de forma individual en cada atributo
con el fin de eliminarlos; (2) los MÃ©todos multivariables que buscan valores atÃ­picos de
instancias mediante la combinaciÃ³n de mÃºltiples atributos; y (3) el MÃ©todo de error de
Minkowski que a diferencia de los otros dos no intenta eliminar los valores atÃ­picos sino
minimizar su impacto en el modelo con el fin de no manipular el conjunto de
entrenamiento como realizan los otros mÃ©todos. Un ejemplo de valores atÃ­picos serÃ­a los
presentando en la Figura 3, donde el valor de los atributos de los valores atÃ­picos (rojo)
difieren del valor que les deberÃ­a corresponder siguiente la trayectoria de la sigmoidal.

12Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
Figura 3: Ejemplo de un conjunto de datos con valores atÃ­picos
â–ª
Sobreajuste: El sobreajuste, sobre aprendizaje u overfitting es el efecto que se produce
al sobreentrenar un modelo mediante un algoritmo de aprendizaje supervisado. Uno de
los problemas. El proceso de aprendizaje debe generar un modelo que permita predecir
el resultado de otras instancias generalizando a partir de lo aprendido mediante la
utilizaciÃ³n de las instancias de entrenamiento. Sin embargo, cuando el conjunto de
entrenamiento se encuentra formado por instancias que no representan de forma global
el problema o estÃ¡ formado por casos muy minoritarios o poco comunes se puede
producir un efecto de sobre entrenamiento. Este efecto hace que el modelo generado
por el algoritmo no sea capaz de generalizar y quede ajustado a unas caracterÃ­sticas
muy especÃ­ficas de los datos de entrenamiento que no tiene relaciÃ³n causal con la
funciÃ³n objetivo.
â–ª
Ruido: El ruido es el conjunto de atributos o valores de un atributo especÃ­fico que no
aportan nada al proceso de aprendizaje y que pueden haber sido introducidos mediante
un proceso de mediciÃ³n incorrecto, un error en la inserciÃ³n de los datos y simplemente
son valores atÃ­picos que puede afectar al proceso de aprendizaje debido a su rareza. Es
decir, es imposible utilizar este conjunto de valores y/o atributos con el fin de generar un
modelo que sea capaz de generalizar en base a las instancias utilizadas para construirlo.
El ruido normalmente aporta muchÃ­simas desventajas a la hora de construir un modelo,
ya que tiende a aumentar la complejidad de los datos complicando la ejecuciÃ³n de los
algoritmos los cuales terminan generando modelos que no generalizan correctamente.
Antes de construir un modelo es muy importante analizar las instancias de entrenamiento
con el fin de eliminar el posible ruido que existe. Este proceso puede ser muy complicado
dependiendo del tamaÃ±o del conjunto de entrenamiento y test, por lo que existen
diferentes aplicaciones que intentan eliminar el ruido de manera automÃ¡tica, aunque este
13
Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
tipo de herramientas no suele asegurar la eliminaciÃ³n total del ruido o incluso pueden
eliminar de manera errÃ³nea informaciÃ³n que es relevante para el proceso de aprendizaje.
â–ª
Sesgo: El sesgo es probablemente uno de los conceptos mÃ¡s importante del Aprendizaje
automÃ¡tico debido a su apariciÃ³n puede producir que nuestros modelos sean inservibles.
El sesgo puede considerarse como un error del modelo generado el cual realiza
predicciones â€œsesgadasâ€ debido a que los datos utilizados para construirlo estÃ¡n
distorsionados de manera directa o indirecta. Un ejemplo tÃ­pico de sesgo que ha
aparecido en muchos de los primeros sistemas basados en visiÃ³n artificial utilizados en
los vehÃ­culos autÃ³nomos donde el proceso de entrenamiento habÃ­a sido sÃ³lo realizado
con adultos de estatura media. Esto producÃ­a que el modelo no fuera capaz de identificar
a los niÃ±os como humanos. En el tema 9 de este curso se harÃ¡ una descripciÃ³n mÃ¡s
detallada del concepto de sesgo y cuÃ¡l es su influencia en las diferentes tÃ©cnicas de
Inteligencia Artificial.
2.4 TÃ©cnicas de Aprendizaje AutomÃ¡tico
Actualmente el Aprendizaje AutomÃ¡tico estÃ¡ formado por un amplio nÃºmero de tÃ©cnicas, las
cuales pueden ser clasificados en cuatro familias de tÃ©cnicas en base a cÃ³mo se encuentra
modelada la informaciÃ³n que usan para definir las entradas y la salida.
â–ª
Supervisado: Este tipo de tÃ©cnicas son denominas como tÃ©cnicas de aprendizaje
mediante profesor debido a que la informaciÃ³n que utilizan durante el proceso de
aprendizaje es completa. Es decir, las instancias de entrenamiento y test estÃ¡ formadas
por atributos que definen las entradas las entradas y la salida esperada para cada
instancia (datos etiquetados). Su funcionamiento consiste en la identificaciÃ³n de una
funciÃ³n (modelo) que sea capaz de realizar un mapeo entre las entradas y las salidas
conocida. Las tÃ©cnicas de este grupo estÃ¡n basadas en clasificaciÃ³n y regresiÃ³n.
â–ª
No supervisado: Este tipos de tÃ©cnicas son mÃ¡s complejas que la anteriores debido a que
la informaciÃ³n que utilizan durante el proceso de aprendizaje es incompleta. Es decir, las
instancias de entrenamiento y test estÃ¡n formadas Ãºnicamente por atributos de entrada.
No se conoce la salida esperada para ninguna de las instancias (datos no etiquetados).
Su funcionamiento consiste en la identificaciÃ³n de una funciÃ³n (modelo) que sea capaz
de agrupar las diferentes instancias en base a ciertas caracterÃ­sticas comunes. Las
tÃ©cnicas de este grupo estÃ¡n basadas en clasificaciÃ³n y agrupamiento.
Â© Structuralia
14Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
â–ª
Semisupervisado: En algunas ocasiones este tipo de tÃ©cnicas son incluidos en uno de los
grupos anteriores ya que la mayor parte de los algoritmos de este grupo puede incluirse
en alguno de los anteriores debido a que aplican algÃºn tipo de transformaciÃ³n en los datos
de entrada con el fin de poder aplicar alguno del algoritmo de los grupos anteriores o
combinan algoritmos de ambos grupos. En mi opiniÃ³n, debe ser clasificados en un grupo
independiente debido a que utilizan informaciÃ³n parcialmente incompleta. Es decir, las
instancias de entrenamiento o test no tienen una estructura totalmente similar debido a
que algunas instancias estÃ¡n etiquetadas y otras no.
Figura 4: DescripciÃ³n de diferentes tÃ©cnicas de Aprendizaje AutomÃ¡tico agrupadas por familia.
â–ª
Por refuerzo: Este es un tipo especial de tÃ©cnicas de aprendizaje automÃ¡tico no
supervisado debido a que utilizan una forma diferente de representaciÃ³n de los ejemplos
de entrenamiento basada en la utilizaciÃ³n de estados y acciones, donde las aplicaciones
de las acciones producen una realimentaciÃ³n en el entorno mediante recompensas. En
el aprendizaje por refuerzo el objetivo consiste en construir una polÃ­tica para resolver un
15
Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
determinado problema. Esta polÃ­tica suele ser una secuencia de acciones que permiten
resolver el problema de manera Ã³ptima.
En la Figura 4 se presentan diferentes tipos de algoritmos de Aprendizaje AutomÃ¡tico distribuidos
por familia (Supervisado, No supervisado y Por refuerzo) y por tÃ©cnica (RegresiÃ³n, ClasificaciÃ³n
y Agrupamiento). En esta figura sÃ³lo se presentan algunos de las tÃ©cnicas mÃ¡s utilizados, pero
existen muchas mÃ¡s e incluso diferentes versiones de cada una de ellas. En rojo se marcan las
diferentes tÃ©cnicas que serÃ¡n descritas de forma detallada en este tema.
3. APRENDIZAJE SUPERVISADO
El aprendizaje supervisado es una de las familias de mÃ©todos de aprendizaje basada en el
aprendizaje inductivo [4] debido a que el proceso de aprendizaje se produce mediante instancias
(ejemplos) etiquetadas. Este tipo de modelo de aprendizaje consiste en definir la informaciÃ³n del
entorno en pares de la forma (entrada â€“ salida) de manera que ante nuevas entradas cuya salida
es desconocida el sistema sea capaz de predecir la salida esperada en base a lo que ha
aprendido durante el proceso de entrenamiento. La entrada se corresponde con las diferentes
caracterÃ­sticas que definen las instancias (ejemplos) y la salida se corresponde con el objetivo
(clase o valor) al que pertenece en ejemplo. El proceso para identificar o definir esta funciÃ³n estÃ¡
dividido en dos fases:
â–ª
Fase de entrenamiento: Es la fase principal del proceso de aprendizaje y consiste en
seleccionar aquellas caracterÃ­sticas mÃ¡s relevantes de cada uno de los ejemplos de
entrada comparÃ¡ndolas con otros ejemplos analizados previamente, mediante algÃºn
proceso de cotejamiento (identificaciÃ³n de patrones), de manera que cuando se detectan
diferencias significativas se produce una adaptaciÃ³n del modelo que estÃ¡ siendo
construido en base al aprendizaje. Este proceso puede ser visto como un sistema de
identificaciÃ³n de patrones mediante la generalizaciÃ³n de las caracterÃ­sticas similares
entre los diferentes ejemplos con el fin de construir un modelo que sea capaz de
identificar los diferentes grupos de ejemplos con caracterÃ­sticas similares. Es decir, el
resultado del proceso de entrenamiento es un sistema formado por un conjunto de
patrones que han sido identificados en base a las caracterÃ­sticas de los ejemplos
utilizados en el proceso de entrenamiento.
â–ª
Fase de test: Esta es la fase secundaria y opcional del proceso de aprendizaje que nos
permite validar el resultado de la fase entrenamiento mediante el uso de ejemplos que

16Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
no han sido utilizados en la fase de entrenamiento con el fin de comprobar. Se suele
considerar cÃ³mo una fase opcional debido a que no puede aplicarse a todos los tipos de
algoritmos de Aprendizaje AutomÃ¡tico.
3.1 Ãrboles de DecisiÃ³n
Un Ã¡rbol de decisiÃ³n (clasificaciÃ³n o regresiÃ³n) es una estructura de datos que permite
representan la informaciÃ³n en forma de un Ã¡rbol. Esta estructura de datos estÃ¡ por formada por
un Ãºnico nodo, denominado raÃ­z, el cual se encuentra conectado a una serie de nodos sucesores
denominados nodos intermedios. Los nodos intermedios tienen un conjunto finito de sucesores
que se encuentran conectados de forma directa con Ã©l mediante un arco o rama. Aquellos nodos
que no tienen ningÃºn sucesor son denominados nodos terminales u hojas. La forma en la que se
va ramificando a nivel espacial esta estructura de datos recuerda a un Ã¡rbol. La construcciÃ³n de
modelos aprendizaje mediante Ã¡rboles de decisiÃ³n es una de las tÃ©cnicas de Aprendizaje
automÃ¡tico basada en el aprendizaje inductivo mÃ¡s utilizada debido principalmente a que son
capaces de construir un predictor mediante un Ã¡rbol n-ario que representa y categoriza una serie
de condiciones en base a las cuales se puede describir las diferentes instancias utilizadas para
construir el Ã¡rbol. AdemÃ¡s, son capaces de representar visualmente el Ã¡rbol resultante podremos
obtener la predicciÃ³n de cualquier nueva instancia sÃ³lo siguiente un camino desde la raÃ­z hasta
uno de los nodos hoja. Este fenÃ³meno permite fÃ¡cilmente comprobar la calidad del modelo, su
homogeneidad, etc. Los Ã¡rboles de decisiÃ³n y regresiÃ³n estÃ¡n formados por tres elementos:
â–ª
Los nodos intermedios, incluida la raÃ­z, que se corresponde con un determinado atributo
de la estructura de las instancias.
â–ª
Los nodos hoja que se corresponden con las clases objetivos que dependiendo de si el
Ã¡rbol es de clasificaciÃ³n o regresiÃ³n serÃ¡n atributos de tipo discreto o continuo
respectivamente.
â–ª
Los arcos (alternativas de la decisiÃ³n) que unen los nodos intermedios con sus sucesores
(nodos intermedios y hojas) que representan los posibles valores de los atributos que han
sido seleccionado para producir el modelo.
17
Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
Figura 5: Ejemplo de Ã¡rbol de decisiÃ³n
En la Figura 5 se presenta un ejemplo de un Ã¡rbol de clasificaciÃ³n que permite decidir si jugar o
no un partido de tenis. Es un Ã¡rbol de clasificaciÃ³n binario debido a todos los nodos hoja (clases)
son de tipo discreto donde los posibles valores que puede tomar el atributo objetivo son dos (SI
o NO). Las diferentes instancias utilizadas para construirlo esta formadas por tres tipos de
atributos (cielo, humedad y viento) cuyos valores son de tipo discreto.
3.1.1. Algoritmo ID3
El algoritmo ID3 (Iterative Dichotomiser 3) [5] es un mÃ©todo de aprendizaje considerado como el
precursor de los algoritmos de la construcciÃ³n de Ã¡rboles de decisiÃ³n ya que muchos de los
diferentes algoritmos de este tipo estÃ¡n basados en Ã©l. Este algoritmo permite crear clasificadores
estadÃ­sticos mediante la construcciÃ³n de Ã¡rboles de decisiÃ³n a partir de instancias con atributos
discretos mediante la utilizaciÃ³n del concepto de entropÃ­a de la teorÃ­a matemÃ¡tica de la
informaciÃ³n [6], la cual permite medir la incertidumbre de un conjunto de informaciÃ³n. Es decir,
nos indica el grado de desordenaciÃ³n de los datos de un conjunto, cuyo valor oscila entre 0 y 1.
La entropÃ­a para la construcciÃ³n de un Ã¡rbol de clasificaciÃ³n binaria para un conjunto de
instancias ğ‘† puede definirse como:
ğ»(ğ‘†) = âˆ’ğ‘(2) log 2 ğ‘(2) âˆ’ ğ‘(1) log 2 ğ‘(1)

18Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
donde p(2) es la fracciÃ³n de ejemplos de la clase 2 en ğ‘† y ğ‘1 es la fracciÃ³n de ejemplos de clase
1 en ğ‘†. Si todos los ejemplos del conjunto S pertenecen sÃ³lo a una de las clases el valor de la
entropÃ­a es 0. En cambio, si los valores de ğ‘0 y ğ‘1 estÃ¡n perfectamente balanceados es decir
tiene un valor 0,5 el valor de la entropÃ­a serÃ­a 1, lo que significa que el conjunto ğ‘† estÃ¡
perfectamente balanceado ya que incluye el mismo nÃºmero de ejemplos de cada clase. Este
concepto de la entropÃ­a se puede generalizar para Ã¡rboles de clasificaciÃ³n multiclase mediante
la siguiente formula, siendo c el nÃºmero de clases:
ğ‘
ğ»(ğ‘†) = âˆ‘ âˆ’ ğ‘(ğ‘–) log 2 ğ‘(ğ‘–)
ğ‘–=1
El valor de la entropÃ­a es utilizado para calcular la ganancia o efectividad de un atributo para
dividir el conjunto de instancias en n subconjuntos (uno por cada posible valor del atributo
seleccionado). La ganancia es el valor esperado de la entropÃ­a tras producir una particiÃ³n del
conjunto de instancia, que se calcula en base a la siguiente formula:
ğº(ğ‘†, ğ´) = ğ»(ğ‘†) âˆ’
âˆ‘
ğ‘£ âˆˆ ğ‘£ğ‘ğ‘™ğ‘œğ‘Ÿğ‘’ğ‘ (ğ´)
|ğ‘†ğ‘£ |
ğ»(ğ‘†ğ‘£ )
|ğ‘†|
Donde A es el atributo seleccionado y ğ‘†ğ‘£ es el conjunto de instancia donde el atributo A tiene el
valor v. El algoritmo ID3 es un proceso recursivo de divide y vencerÃ¡s que intenta minimizar el
valor de la entropÃ­a con el fin de conseguir Ã¡rboles de menor tamaÃ±o. El funcionamiento del
algoritmo consiste en un proceso de bÃºsqueda avariciosa o voraz sobre diferentes subconjuntos
de conjunto S, el cual estÃ¡ formado por las todas las instancias del problema, utilizando con
medida de estimaciÃ³n la ganancia (heurÃ­stica). El algoritmo comienza calculando el valor de la
entropÃ­a de cada uno de los atributos no seleccionados de los elementos del conjunto S (todos
en el paso inicial), seleccionÃ¡ndose aquel atributo que tiene el menor valor de entropÃ­a (mayor
ganancia de informaciÃ³n). Se crea un nodo del Ã¡rbol para el atributo seleccionado y a
continuaciÃ³n el conjunto S es dividido o particionado en n subconjuntos en base a los posibles
valores del atributo. Para cada uno de los subconjuntos generado se aplica el mismo proceso
calculÃ¡ndose el valor de la ganancia para todos los atributos y se seleccionado aquel atributo
que minimiza la entropÃ­a hasta que:
âœ“ Todos los elementos del subconjunto pertenen a la misma clase, por lo que se crea un
nodo de tipo hoja y se le etiqueta con la clase.
19
Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
âœ“ No existe ningÃºn otro atributo que seleccionar, por lo que se crea un nodo de tipo hoja y
se les etiqueta la clase mayoritaria a todos los elementos del subconjunto.
El proceso continuo hasta que todos los elementos del conjunto S hayan sido asignados a un
nodo hoja. El funcionamiento de este algoritmo fue mejorado a travÃ©s de mÃºltiples versiones
(ID4[7] e ID5r[4]) con el fin de mejorar el funcionamiento y el rendimiento del algoritmo.
3.1.2. Algoritmo CART
El algoritmo CART (Classification and Regression Trees) [8] es un mÃ©todo de aprendizaje que
permite crear clasificadores y regresores estadÃ­sticos mediante la construcciÃ³n de Ã¡rboles de
decisiÃ³n (clasificaciÃ³n y regresiÃ³n) a partir de instancias con atributos discretos y continuos
mediante la utilizaciÃ³n del concepto de impureza que define la homogeneidad de cada nodo. Es
decir, el concepto de impureza define como similares son los elementos de un conjunto en base
a un determinado criterio que en este caso es una de las posibles clases. El valor de impureza
se calcula de manera diferentes dependiendo del tipo de Ã¡rbol que se estÃ© creando:
â–ª
ClasificaciÃ³n: La impureza para el proceso de generaciÃ³n de un Ã¡rbol de clasificaciÃ³n
puede ser calculada en base a la entropÃ­a o en base al indice de diversidad de Gini, el
cula puede ser calculado en base a la siguiente fÃ³rmula para clasificaciÃ³n binaria:
ğ‘–(ğ‘†) = ğ‘(1) ğ‘(2)
donde p(1) es la fracciÃ³n de ejemplos de la clase 1 en S y p(2) es la fracciÃ³n de ejemplos
de clase 2 en S. El cÃ¡lculo de la impureza puede ser extendido para clasiciaciÃ³n multiclase
utilizando la siguiente formula, siendo c el nÃºmero de clases:
ğ‘
ğ‘–(ğ‘†) = âˆ‘ ğ‘(ğ‘–) ğ‘(ğ‘—)
ğ‘– â‰ ğ‘—
â–ª
RegresiÃ³n: La impureza para el proceso de generaciÃ³n de un Ã¡rbol de regresiÃ³n se
calcula como la agregaciÃ³n de las varianzas de todos los nodos terminales.
Â© Structuralia
20Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
El algoritmo CART es un proceso formado por dos fases que generan un Ã¡rbol, denominado
saturado, que posteriormente es optimizado mediante la aplicaciÃ³n de diferentes tÃ©cnicas de
poda.
â–ª
GeneraciÃ³n de un Ã¡rbol saturado mediante un algoritmo recursivo de divide y vencerÃ¡s
que intenta minimizar el valor de la impureza de los nodos del Ã¡rbol con el fin de conseguir
una mayor homogeneidad en los ejemplos que pertenecen a cada uno de los nodos del
Ã¡rbol. Este proceso tiende a generar Ã¡rboles de gran profundidad debido a que se han
intentado crear nodos que representan instancias con la mayor homogeneidad posible.
â–ª
OptimizaciÃ³n del Ã¡rbol mediante un proceso de poda. La poda consiste en encontrar el
subÃ¡rbol del Ã¡rbol saturado con la mejor calidad en base a la ratio de predicciÃ³n de los
resultados y menor vulnerabilidad al ruido de las instancias de entrada (entrenamiento).
Para ello se realiza un anÃ¡lisis de calidad de los nodos terminales de los posibles
subÃ¡rboles del Ã¡rbol saturado. Para un Ã¡rbol T se define la calidad en base a la siguiente
formula:
ğ‘(ğ‘‡) = âˆ‘ ğ‘[ğ‘¡]ğ‘Ÿ(ğ‘¡)
ğ‘¡ ğœ– ğ‘‡Ìƒ
donde ğ‘‡Ìƒ es el conjunto de nodos terminales del Ã¡rbol T y r(t) es una medida de calidad
del nodo t la cual es similar a la suma de los cuadrados de los residuales en regresiÃ³n
lineal. Es posible utilizar la inpureza del nodo t como medida de la calidad.
Este proceso de generaciÃ³n de Ã¡rboles puede ser utilizado para la generaciÃ³n tanto de Ã¡rboles
de regresiÃ³n como de clasificaciÃ³n variando la forma en la que se calcula la impureza y la calidad
de los nodos terminales para el proceso de poda.
3.1.3. Algoritmo C4.5
El algoritmo C4.5[9], denominado J48 en su versiÃ³n open source utilizada en muchos frameworks
de aprendizaje, es un mÃ©todo de aprendizaje que mejora las diferentes versiones del algoritmo
ID3 que permite crear clasificadores estadÃ­sticos mediante la construcciÃ³n de Ã¡rboles de decisiÃ³n
a partir de instancias con atributos discretos y continuos. Este mÃ©todo incluye importantes
mejoras que resuelven algunos de los problemas que tenÃ­an sus antecesores siendo el mÃ¡s
importante de ellos la posibilidad de utilizar atributos continuos. Para ello, el algoritmo realiza un
21
Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
anÃ¡lisis de los atributos de las instancias de entrada con el fin de discretizar los atributos
mediante su separaciÃ³n en rangos en base a los valores de las instancias de entrada. AdemÃ¡s
incluye dos importante mejoras con el fin de optimizar el proceso de generaciÃ³n y evitar el
sobreaprendizaje: (1) Permite la utilizaciÃ³n de procesos de poda (simplificaciÃ³n del tamaÃ±o del
Ã¡rbol) durante (se detiene el proceso de subdivisiÃ³n den base a algÃºn criterio) y al finalizar (se
realiza una serie de modificaciones sobre el Ã¡rbol de forma que ciertas ramas se fusionan o se
transforman en nodos hoja) el proceso de generaciÃ³n; y (2) Permite ignorar los datos atributos
perdidos durante el proceso de generaciÃ³n, es decir no se tienen en cuenta aquellas instancias
que no tienen valor para el atributo que se estÃ¡ analizando.
Al igual que su antecesor, el algoritmo C4.5 es un proceso recursivo de divide y vencerÃ¡s que
intenta minimizar el valor de la entropÃ­a, pero introduciendo una nueva medida de la ganancia,
denominado ratio de ganancia, que permite calcular de forma mÃ¡s eficiente la ganancia de elegir
un atributo.
ğ‘Ÿğ‘ğ‘¡ğ‘–ğ‘œ(ğ‘†, ğ´) =
ğ»ğ‘ğ‘ğ‘Ÿğ‘ğ‘–ğ‘ğ‘™ (ğ‘†, ğ´) = âˆ’
ğº(ğ‘†, ğ´)
ğ»ğ‘ğ‘ğ‘Ÿğ‘ğ‘–ğ‘ğ‘™ (ğ‘†, ğ´)
âˆ‘
ğ‘£ âˆˆ ğ‘£ğ‘ğ‘™ğ‘œğ‘Ÿğ‘’ğ‘ (ğ´)
|ğ‘†ğ‘£ |
|ğ‘†ğ‘£ |
log 2
|ğ‘†|
|ğ‘†|
El funcionamiento del algoritmo es similar al de ID3 salvo en la forma de calcular la ganancia de
cada atributo donde se utilizan las dos formular presentadas previamente y en la fase de
generaciÃ³n de los diferentes subconjuntos donde C4.5 genera nodos intermedios u hojas se
introducen nuevos casos base con el fin de mejorar el tamaÃ±o del Ã¡rbol como por ejemplo en
situaciones donde no se obtiene ninguna ganancia de informaciÃ³n para ninguno de los
subconjuntos generados en base a los valores del atributo. En estos casos, se crea un nodo
intermedio mÃ¡s arriba del Ã¡rbol utilizando el valor esperado de la clase. El algoritmo C4.5 ha sido
mejorado dando lugar a diferentes versiones (C5.0 y See5) con el fin de mejorar su
funcionamiento (velocidad y uso de memoria) y aÃ±adir mÃ¡s funcionales que permiten construir
Ã¡rboles de menor tamaÃ±o o que eliminan atributos que no son utilizados en el proceso de
clasificaciÃ³n.

22Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
3.2 Bosques aleatorios (Random Forest)
Los bosques aleatorios o los bosques de decisiÃ³n [17] aleatorios son un mÃ©todo de aprendizaje
para la generaciÃ³n de clasificadores o regresores basados en Ã¡rboles de decisiÃ³n que fueron
definidos para evitar el proceso de sobreajuste de los modelos producidos por las diferentes
tÃ©cnicas de generaciÃ³n de Ã¡rboles de decisiÃ³n. Este mÃ©todo funciona mediante la generaciÃ³n de
una poblaciÃ³n aleatoria de Ã¡rboles de decisiÃ³n que son utilizados para decidir en comÃºn el valor
la variable de salida. Dependiendo del tipo de Ã¡rboles de poblaciÃ³n el proceso decisiÃ³n serÃ¡
diferente. Para una poblaciÃ³n formada por Ã¡rboles de clasificaciÃ³n se realizarÃ¡ un proceso de
votaciÃ³n siendo la clase mayoritariamente predicha la salida del mÃ©todo. En cambio, para una
poblaciÃ³n formada por Ã¡rboles de regresiÃ³n se calcula la media de las predicciones de cada uno
de los Ã¡rboles. En la Figura 6 se muestra un ejemplo del funcionamiento de clasificador o
regresor construido mediante bosque de Ã¡rboles aleatorios.
Figura 6: Ejemplo de funcionamiento de un bosque de decisiÃ³n aleatorio
El proceso de generaciÃ³n de un bosque de decisiÃ³n aleatorio consiste en manipular el conjunto
de entrada (entrenamiento) con el fin de generar un conjunto de entrada aleatorios que serÃ¡n
utilizados para entrenar cada uno de los Ã¡rboles del bosque. Para el proceso de generaciÃ³n de
23
Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
los conjuntos de entrenamiento se utiliza un algoritmo de Bootstrap aggregating, tambiÃ©n
denominado algoritmo de embolsamiento (bagging en inglÃ©s). Dado un conjunto de entrenamiento E
con un nÃºmero n de elementos el algoritmo de embolsamiento generarÃ¡ m conjuntos de
entrenamiento de tamaÃ±o n mediante la selecciÃ³n uniforme de instancias del conjunto E. Este sistema
de generaciÃ³n basado en un muestreo con remplazo implica que algunas que una parte de las
instancias que forman los diferentes conjuntos de entrenamiento estarÃ¡n repetidas. Cada uno de
estos conjuntos serÃ¡ utilizado para construir un Ã¡rbol de decisiÃ³n, los cuales pueden ser generados
por medio de tÃ©cnicas diferentes. Una vez definidos todos los Ã¡rboles (modelos) son combinados con
el fin de generar una predicciÃ³n comÃºn calculada promediando la salida (para regresiÃ³n) o votando
(para clasificaciÃ³n).
3.3 RegresiÃ³n lineal
La regresiÃ³n lineal es un mÃ©todo matemÃ¡tico utilizado para estudiar la relaciÃ³n entre un conjunto
de variables independientes (variables predictoras) y una variable dependiente (criterio o variable
predecida) [18]. Dependiendo del nÃºmero de variables independientes utilizadas en el proceso
de predicciÃ³n se pueden diferenciar entre regresiÃ³n simple cuando sÃ³lo utilizamos una variable
dependiente y regresiÃ³n mÃºltiple cuando utilizamos mÃ¡s de una variable independiente. Esta
tÃ©cnica permite desarrollar una ecuaciÃ³n lineal que puede ser utilizada para construir un modelo
de predicciÃ³n a partir de instancias con atributos discretos de entrada y salida.
3.3.1. RegresiÃ³n lineal simple
La regresiÃ³n lineal simple consiste en calcular una ecuaciÃ³n lineal que relaciona una variable
independiente x y una variable dependiente y. La ecuaciÃ³n lineal que debe ser calculada tiene la
siguiente estructura:
ğ‘¦ = ğ›½0 + ğ›½1 ğ‘¥ + ğœ€
donde y es la variable dependiente que queremos predecir en base a todas las demÃ¡s, ğ›½0 y
ğ›½1 son parÃ¡metros desconocidos que deben ser calculado, x es la variable independiente y ğœ€ es
el error cometido en la predicciÃ³n. El proceso de aprendizaje consistirÃ­a en utilizar instancias de
entrada (entrenamiento), compuestas cada una por dos valores uno para la variable
independiente x y otro para la variable dependiente, para calcular los valores ğ›½0 y ğ›½1 que darÃ­an
lugar a la ecuaciÃ³n de una recta donde ğ›½0 serÃ­a la ordenada en el origen, es decir es la altura a

24Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
la que la recta corte el eje Y, y ğ›½1 es la pendiente de la recta, es decir es el incremento o
decremento que se produce en la variable y cuando la variable x aumenta o disminuye una
unidad. La Figura presenta el resultado de un proceso de regresiÃ³n simple que consiste en
aproximar una recta de regresiÃ³n que se ajuste mejor la nube de puntos producidas por los
valores utilizados para calcularla.
Figura 7: Ejemplo de la recta resultante de un proceso de regresiÃ³n lineal simple
Uno de los grandes problemas de esta tÃ©cnica es que dado un conjunto de instancias de entrada
(entrenamiento) existen infinitas rectas que pueden pasar por la nube de puntos por lo que es
necesario elegir la recta que pasa lo mÃ¡s cerca posible de la mayor parte de los puntos. Por lo
que el objetivo de aprendizaje consiste en encontrar la recta que represente mejor el conjunto de
puntos. Existen diferentes tÃ©cnicas matemÃ¡ticas que permiten ajustar una funciÃ³n simple, siendo
la mÃ¡s utilizada la tÃ©cnica de mÃ­nimos cuadrados que permite identificar la recta que hace mÃ­nima
la suma de los cuadrados de las distancias verticales entre cada punto y la recta.
3.3.2. RegresiÃ³n lineal mÃºltiple
La regresiÃ³n lineal simple es un caso particular de la regresiÃ³n lineal mÃºltiple que consiste en
calcular una ecuaciÃ³n que relaciona un conjunto de variables independientes x1, x2, â€¦, xn y una
variable dependiente y. La ecuaciÃ³n para este caso de regresiÃ³n tiene la siguiente estructura:
25
Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
ğ‘¦ = ğ›½0 + ğ›½1 ğ‘¥1 + ğ›½2 ğ‘¥2 + â‹¯ + ğ›½ğ‘› ğ‘¥ğ‘› + ğœ€
El funcionamiento de la regresiÃ³n lineal mÃºltiple es exactamente similar a la regresiÃ³n lineal
simple salvo con la diferencia de que tenemos mÃºltiples variables independiente y de que la
ecuaciÃ³n no representa una recta, sino que representarÃ¡ un plano cuando tengamos dos
variables independientes, un espacio tridimensional cuando tenemos tres variables
independientes y un hiperespacio cuando tengamos mÃ¡s de tres variables.
3.4 Redes de Neuronas Artificiales
Una Red de Neuronas Artificial (RNA) es una red representada de manera espacial mediante un
grafo dirigido donde cada uno de los nodos representan neuronas y los arcos representan las
sinapsis o conexiones entre las neuronas [19]. Esta estructura intenta imitar la distribuciÃ³n de las
neuronas en el cerebro humano con el fin de construir un tipo de algoritmo que sea capaz de
simular la capacidad de procesamiento de nuestros cerebros. Para ello es necesario realizar una
breve introducciÃ³n de la estructura de una neurona humana con el fin de entender cuales sus
similitudes. Las neuronas fueron descubiertas o identificadas por el cientÃ­fico espaÃ±ol RamÃ³n y
Cajal en 1888, donde definiÃ³ el cerebro como una red de aproximadamente 100 * 106 cÃ©lulas
individuales, denominadas neuronas, ampliamente interconectadas entre sÃ­. Las neuronas
humanas estÃ¡n formadas por tres elementos: (1) el soma o cuerpo celular es la parte principal
de la neuronas (10 a 80 micras de longitud); (2) las mÃºltiples prolongaciones que salen de
distintas partes del soma, denominadas dendritas, cuya funciÃ³n consiste en recibir impulsos de
otras neuronas y enviarlos hasta el soma; y (I3) el axÃ³n, que es una prolongaciÃ³n del soma que
se extiende en direcciÃ³n opuesta a las dendritas y tiene la funciÃ³n de conducir un impulso
nervioso desde el soma hacia otra neurona, mÃºsculo o glÃ¡ndula del cuerpo humano. La Figura
8 presenta la estructura detallada de una neurona humana y sus diferentes partes.

26Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
Figura 8: Estructura biolÃ³gica de una neurona
En base a esta estructura biolÃ³gica, los investigadores Pitts y McCulloch definieron el primer
modelo de red neuronal en 1943[20]. Este modelo consistÃ­a en una red con dos capas de
neuronas conectadas entre sÃ­, donde la primera capa estaba formada por conjunto de nodos o
neuronas formales (neuronas presinÃ¡pticas) que representaban la entrada de la red y la segunda
capa estaba formada por un Ãºnico nodo o neurona formal (neurona postsinÃ¡ptica) que
representaba la salida de la red. Una neurona formal era una puerta lÃ³gica con dos posibles
estados internos (encendido o apagado) representados por una variable. Esta red funcionaba
como un discriminador del estado de la puerta lÃ³gica, de forma que las neuronas de la primera
capa recibÃ­an las entradas, que eran enviadas a la segunda capa donde se aplicaba una
operaciÃ³n matemÃ¡tica obteniÃ©ndose un valor sobre el cual se aplicaba una funciÃ³n que
activaciÃ³n, basada en un umbral, que definÃ­a el estado de la salida. Es decir, si el valor obtenido
de la operaciÃ³n sobre las entradas era mayor que el umbral la salida era 1 y sino la salida era 0.
A partir de este y otros modelos que se desarrollaron en los siguientes aÃ±os, Rumelhart y
McClelland introdujeron en 1986 lo que se conoce actualmente como el modelo estÃ¡ndar de
neurona artificial, el cual se encuentra representado en la Figura , donde se presentan los
componentes de una neurona artificial, asÃ­ como la correspondencia entre los elementos de una
neurona biolÃ³gica y una neurona artificial. Como se puede observar en la imagen la neurona
artificial intenta imitar de forma completa la estructura de la neurona biolÃ³gica.
27
Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
Figura 9: Elementos bÃ¡sicos de una neurona artificial
â–ª
Un conjunto de entradas xj y un conjunto de pesos wij, denominados sinÃ¡pticos, donde j
es un valor entre 1 y n.
â–ª
Una funciÃ³n de propagaciÃ³n hi definida a partir del conjunto de entradas y los pesos
sinÃ¡pticos. Es decir:
â„ğ‘– (ğ‘¥1 , â€¦ , ğ‘¥ğ‘› , ğ‘¤ğ‘–1 , â€¦ , ğ‘¤ğ‘–ğ‘› )
La funciÃ³n de propagaciÃ³n define la operaciÃ³n matemÃ¡tica mediante la cual se combinan
las diferentes entradas que recibe la neurona. La funciÃ³n de propagaciÃ³n mÃ¡s
comÃºnmente utilizada consiste en combinar linealmente las entradas y los pesos
sinÃ¡pticos, mediante la siguiente operaciÃ³n matemÃ¡tica:
ğ‘›
â„ğ‘– (ğ‘¥1 , â€¦ , ğ‘¥ğ‘› , ğ‘¤ğ‘–1 , â€¦ , ğ‘¤ğ‘–ğ‘› ) = âˆ‘ ğ‘¤ğ‘–ğ‘— ğ‘¥ğ‘—
ğ‘–=1
AdemÃ¡s, es muy comÃºn aÃ±adir a la funciÃ³n de propagaciÃ³n un parÃ¡metro adicional Î¸i,
que comÃºnmente denomina umbral, el cual se suele restar al resultado de la operaciÃ³n
ğ‘›
â„ğ‘– (ğ‘¥1 , â€¦ , ğ‘¥ğ‘› , ğ‘¤ğ‘–1 , â€¦ , ğ‘¤ğ‘–ğ‘› ) = âˆ‘ ğ‘¤ğ‘–ğ‘— ğ‘¥ğ‘— âˆ’ Î¸ğ‘–
ğ‘–=1
â–ª
Una funciÃ³n de activaciÃ³n, que representa simultÃ¡neamente la salida de la neurona y su
estado de activaciÃ³n. De forma matemÃ¡tica la funciÃ³n de activaciÃ³n se puede definir:

28Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
ğ‘›
ğ‘¦ğ‘– = ğ‘“ğ‘– (ğ‘¥ğ‘– ) = ğ‘“ğ‘– (âˆ‘ ğ‘¤ğ‘–ğ‘— ğ‘¥ğ‘— )
ğ‘–=1
En la Tabla 2 se presentan algunas de las funciones de activaviÃ³n mÃ¡s comunes utilizadas
por la red de neuronas. Normalmente se usan diferentes tipos de funciones de activaciÃ³n
para cada una de las capas de la red.
NombreFunciÃ³nRango
Identidadğ‘¦=ğ‘¥[âˆ’âˆ, +âˆ]
ğ‘¦ = ğ‘ ğ‘–ğ‘”ğ‘›(ğ‘¥){âˆ’1, +1}
ğ‘¦ = ğ»(ğ‘¥){0, +1}
âˆ’1, ğ‘ ğ‘– ğ‘¥ < âˆ’ğ‘™
= {ğ‘¥, ğ‘ ğ‘– + ğ‘™ â‰¤ ğ‘¥ â‰¤ âˆ’ğ‘™
+1, ğ‘ ğ‘– ğ‘¥ < +ğ‘™[âˆ’1, +1]
GrÃ¡fica
EscalÃ³n
ğ‘¦
Lineal
Sigmoidea
29
ğ‘¦=
1
1 + ğ‘’ âˆ’ğ‘¥
[0, +1]
Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
ğ‘¦ = tanh(ğ‘¥)
2
Gausianağ‘¦ = ğ´ğ‘’ âˆ’ğµğ‘¥
Sinusoidalğ‘¦ = ğ´ sin(ğœ”ğ‘¥ + ğœ‘)
Softmax
ğ‘¦=
ğ‘’ ğ‘¥ğ‘–
âˆ‘ğ‘–ğ‘—=1 ğ‘’ ğ‘¥ğ‘—
[âˆ’1, +1]
[0, +1]
[âˆ’1, +1]
[0, +1]
Tabla 2 - Funciones de activaciÃ³n mÃ¡s comunes
3.4.1. Arquitecturas de las redes de neuronas
Una vez definidos los componentes bÃ¡sicos, es decir las neuronas, es necesario definir como se
encuentran distribuidos y conectadas en la red. La distribuciÃ³n de las diferentes conexiones de
la red determina en gran medida el funcionamiento de la red de neuronas. Los distintos nodos
(neuronas) que componen la red se encuentran conectados entre sÃ­ mediante las sinapsis. Estas
conexiones son unidireccionales, es decir, la informaciÃ³n sÃ³lo se propaga en un Ãºnico sentido
desde la neurona presinÃ¡ptica a la neurona postinÃ¡ptica. En general, las neuronas se agrupan

30Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
entre sÃ­ en base a la funciÃ³n de propagaciÃ³n que utilizan en entidades mÃ¡s grandes denominadas
capas. La combinaciÃ³n secuencial de diferentes capas constituye una red de neuronas artificial.
En cualquier red de neuronas artificial se pueden distinguir tres tipos de capas:
â–ª
Capa de entrada o sensorial: Es la capa inicial de la red de neuronas y estÃ¡ compuesta
por neuronas que reciben informaciÃ³n (datos o seÃ±ales) del entorno.
â–ª
Capa de salida: Es la capa final de la red de neuronas y genera la salidad o respuesta de
la red.
â–ª
Capa oculta: Es la capa o capas intermedias de la red de neuronas donde se realizan las
diferentes operaciones matemÃ¡ticas que permiten a la red procesar y manipular la
informaciÃ³n con el fin de generar la salida de la red de neuronas. El caso mÃ¡s sencillo es
que sÃ³lo exista una capa, pero pueden incluirse todas las capas que sean necesarias. La
inclusiÃ³n de mÃºltiples capas ocultas ha dado lugar a las redes de neuronas profundas
que se han popularizado en los Ãºltimos aÃ±os mediante el Aprendizaje profundo (Deep
Learning). Aunque este tipo de arquitecturas son muy eficientes para ciertos procesos
aumenta en gran medida la complejidad de la red de neuronas.
En la Figura 10 se presenta un ejemplo de una red de neuronas unidireccional compuesta por 4
capas (red multicapa), donde se presenta una capa con tres neuronas de entrada, dos capas
ocultas con 4 neuronas completamente conectadas y una capa de salida con 2 neuronas.
Figura 10: Ejemplo de una red multicapa formada por una capa de entrada, 2 capas ocultas y una capa de salida
31
Â© StructuraliaInteligencia artificial â€“ Aprendizaje automÃ¡tico I
Dependiendo del nÃºmero de capas ocultas que incluyamos en nuestra de red de neuronas
artificial podemos hablar de redes monocapa que sÃ³lo estÃ¡n compuesta por una Ãºnica capa
oculta o redes multicapa donde existen mÃºltiples capas ocultas. AdemÃ¡s, dependiendo de las
conexiones entre las diferentes capas podemos distinguir entre tres tipos de redes de neuronas
artificiales:
âœ“ Redes Unidireccionales (feedforward): Las redes de neuronas unidireccionales o
prealimientadas (debido a que las neuronas obtienen informaciÃ³n de la capa anterior o
del entorno) son las primera y mÃ¡s sencilla estructura de red neuronal artificial construida
por el ser humano. Es esta estructura de red, la informaciÃ³n se mueve en una Ãºnica
direcciÃ³n. Es decir, de la capa de entrada, a travÃ©s de las diferentes capas ocultas (si
existen) hacia las capas de salida. En este tipo de redes no existe ningÃºn tipo de bucle o
retroalimentaciÃ³n hacia atrÃ¡s. Este tipo de redes, a pesar de su sencillez, ofrecen muy
buenos resultados en procesos en los cuales no se requiera el uso de informaciÃ³n de
eventos futuros dentro de la red.
âœ“ Redes Elman (simple feeback): Las redes de neuronas Elman son denominadas redes
recurrentes simples ya que incluyen retroalimentaciÃ³n entre las capas contiguas. Es decir,
en este tipo de red poseen una memoria de los eventos inmediatamente anteriores. Esta
informaciÃ³n es utilizada en el proceso de actualizaciÃ³n de los pesos durante el proceso
de apredizaje.
âœ“ Redes recurrentes (full feedback): Las redes de neuronas recurrentes completamente
conectadas, a diferencia de las redes de neuronas Elman, tienen conexiones de
retroalimentaciÃ³n a todos los elementos que forman la red. Cada neurona de la red estÃ¡
conectada a todos los elementos que la rodean desde un punto de vista espacial. Es
decir, una neurona estÃ¡ conectada a las neuronas de las capas posterioes y anteriores y
a sÃ­ misma.
3.4.2. Proceso de entrenamiento
Una vez que se ha definido la estructura de la red de neuronas es necesario computar el valor
de los diferentes pesos de cada una de las capas de la red, para ello se utiliza un proceso de
entrenamiento compuesto por dos fases:
â–ª
Fase de entrenamiento: En esta fase se calcula el valor de los pesos de la red, para ello
se utiliza un conjunto de datos o patrones (ejemplos de entrenamiento) que se utilizan
para calcular los pesos (parÃ¡metros) que definen el modelo de la red de neuronas. Los
Â© Structuralia
32Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
diferentes pesos son calculados de manera iterativa, de acuerdo con los valores de los
ejemplos entrenamiento, con el objeto de minimizar el error cometido entre la salida
obtenida por la red neuronal y la salida deseada.
â–ª
Fase de test: En esta se realiza un analisis de la calidad del proceso de entrenamiento,
es decir se analiza si el modelo construido en la fase anterior es capaz de generalizar a
casos nuevos o se ha ajustado demasiado a las particularidades presentes en los
ejemplos de entrenamiento (sobreajuste). Para evitar el problema del sobreajuste, es
aconsejable utilizar un segundo grupo de datos diferentes a los de entrenamiento, el
grupo de validaciÃ³n, que permita controlar el proceso de cÃ¡lculo de los pesos.
3.4.3. Tipos de redes neuronas
Las redes de neuronas se pueden construir de diferentes maneras dependiendo del nÃºmero de
capas, el tipo de neuronas utilizadas y la forma en la que estÃ¡n conectadas las diferentes capas.
Pero existen una serie de configuraciones bÃ¡sicas que identifican ciertos tipos de redes de
neuronas, algunas de las cuales son descritas a continuaciÃ³n:
â–ª
PerceptrÃ³n simple: El perceptrÃ³n (Perceptron, P en sus siglas en inglÃ©s) es la red de
neuronas mÃ¡s sencilla formada por sÃ³lo dos capas (entrada y salida) que permite
construir un discriminador simple.
â–ª
PerceptrÃ³n multicapa: El perceptrÃ³n multicapa (Multilayer Perceptron MP, en sus siglas
en inglÃ©s) es una red de neuronas basada en el perceptrÃ³n simple que introduce el concepto
de capa oculta. La estructura bÃ¡sica de esta red estÃ¡ formada por al menos tres capas
(entrada, oculta y salida) cuya interacciÃ³n permite construir un aproximador de tipo universal.
Es decir, permite aproximar cualquier tipo de funciÃ³n continua definida en un espacio ğ‘… ğ‘› .
â–ª
Redes recurrentes: Las redes de neuronas recurrentes (Recurrent Neural Networks, RNN
en sus siglas en inglÃ©s) son una extensiÃ³n del perceptrÃ³n multicapa donde se producen
conexiones entre las neuronas en ambos sentidos (hacia delante y hacia atrÃ¡s). Existe
dos tipos de redes recurrentes: simples que sÃ³lo tienen conexiÃ³n con las neuronas de las
capas continuas; y completas que pueden estar conectadas con todas las neuronas de
las diferentes capas incluidas ellas mismas.
â–ª
Redes largas de memoria a corto plazo: Las redes de neuronas largas con memoria a
corto plazo (Long Short-Term Memory, LSTM en sus siglas en inglÃ©s) son un tipo de red
de neuronas que incluye bloques de memoria que permite recordar cierto tipo de
informaciÃ³n.
33
Â© StructuraliaInteligencia artificial â€“ Aprendizaje automÃ¡tico I
â–ª
Redes convolucionales: Las redes de neuronas convolucionales (Convolutional Neural
Networks, CNN en sus siglas en inglÃ©s) son un tipo de red de neuronas similar al
perceptrÃ³n multicapa donde las neuronas de algunas de sus capas son de tipo
convolucional, de reducciÃ³n del muestreo y sencillas. Las neuronas convolucionales
tratan de simular el funcionamiento de las neuronas de la corteza visual humana mediante
la aplicaciÃ³n de filtros (operaciones matriciales) que permiten la extracciÃ³n de
caracterÃ­sticas de los datos de entradas que se corresponden con los pÃ­xeles de una
imagen.
â–ª
Redes generativas antagÃ³nicas: Las redes de neuronas generativas antagÃ³nicas
(Generative Adversarial Network, GAN en sus siglas en inglÃ©s) son una combinaciÃ³n de
dos redes de neuronas que compiten mutuamente en un juego de suma cero. El cual
consiste una situaciÃ³n en la que la ganancia o pÃ©rdida de un participante se equilibra con
exactitud con las pÃ©rdidas o ganancias del otro participante.
3.5 K-Nearest Neighbour
El algoritmo de K-vecinos mÃ¡s cercanos (K-Nearest Neighbour, KNN en sus siglas en inglÃ©s) es
un metodo de aprendizaje no parametrizado para la generaciÃ³n de clasificadores o regresores
basados en el concepto de cercanÃ­a [16]. Este algoritmo no produce ningÃºn tipo de modelo tras
la fase de aprendizaje, sino que almacena todas las instancias utilizadas para el proceso de
aprendizaje en una estructura de datos que es consultada con el fin de predecir el valor de salida
(clase o valor) de nuevas instancias.
Â© Structuralia
34Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
Figura 11: Ejemplo del funcionamiento del proceso de clasificaciÃ³n del
algoritmo KNN utilizando un diferente valor de K.
El funcionamiento del algoritmo es muy sencillo una vez que se ha producido la generaciÃ³n de
la estructura de datos que almacena las instancias de entrenamiento. Dada una nueva instancia
que debe ser clasificada se calcula la distancia a todas las instancias almacenadas en la
estructura de datos, las cuales son ordenadas en base al valor de distancia obtenido de menor
a mayor. A continuaciÃ³n, se seleccionan las k instancias mÃ¡s cercanas y se asigna a la nueva
instancia la clase mÃ¡s frecuente de entre las instancias seleccionadas como mÃ¡s cercanas en el
caso de que se estÃ© realizando un proceso de clasificaciÃ³n; o se pondera el valor de salida en
base a los valores de las instancias seleccionadas como mÃ¡s cercanas en el caso de que se estÃ©
realizando un proceso de regresiÃ³n. En la Figura 11 se presenta un ejemplo visual de un proceso
de clasificaciÃ³n para una nueva instancia utilizando un algoritmo KNN de forma que se calcula la
distancia al resto de instancia. En este caso se puede observar como el valor de la clase de la
nueva instancia varÃ­a dependiendo del valor de k que seleccionemos.
â–ª
Para k = 1 la nueva instancia (negro) serÃ­a clasificada como azul ya que la instancia mÃ¡s
cerca es azul.
â–ª
Para k = 2 la nueva instancia (negro) podrÃ­a ser clasificada como roja o como azul ya que
las dos instancias mÃ¡s cercanas pertenecen a dos clases diferentes. SerÃ­a necesario
definir algÃºn tipo de tÃ©cnica que permitiera eliminar el empate.
â–ª
Para k = 3 la nueva instancia (negro) serÃ­a clasificada como roja ya que de las tres
instancias mÃ¡s cercanas dos son rojas y una es azul.
35
Â© StructuraliaInteligencia artificial â€“ Aprendizaje automÃ¡tico I
Teniendo en cuenta el funcionamiento observado en el ejemplo descrito en la Figura 11 es
necesario configurar el algoritmo KNN en base a dos elementos:
â–ª
El valor k que suele ser seleccionado manual tras el proceso de aprendizaje, pero en
algunos casos en posible calcular el valor mediante algÃºn tipo de algoritmo en base a la
distribuciÃ³n de las instancias del conjunto de entrenamiento.
â–ª
La funciÃ³n de cÃ¡lculo de la distancia que permitirÃ¡ definir la similitud entre dos instancias.
La funciÃ³n mÃ¡s comÃºn es la distancia euclidea presentada en la siguiente ecuaciÃ³n
ğ‘
ğ‘‘(ğ‘¥ğ‘– , ğ‘¥ğ‘— ) = âˆšâˆ‘(ğ‘¥ğ‘Ÿğ‘– âˆ’ ğ‘¥ğ‘Ÿğ‘— )2
ğ‘Ÿ=1
KNN es uno de los algoritmos mÃ¡s utilizados para clasificaciÃ³n debido principalmente a su
sencillez. El tiempo de clasficiaciÃ³n de nuevas instancias puede ser muy elevado si el conjunto
de instancias de entrenamiento es muy grande, debido a que se debe realizar el calculo de la
distancia con todos los elementos almacenados en la estructura de datos durante el proceso de
aprendizaje. Existen diferentes versiones del algoritmo KNN que intentan explotar los dos
elementos que pueden ser configurados, algunas de estas versiones son: (1) KNN con rechazo;
(2) KNN con distancia media; y (3) KNN con distancia mÃ­nima.
4. CONCLUSIONES
El Aprendizaje AutomÃ¡tico es una las tÃ©cnicas mÃ¡s prometedoras de la inteligencia artificial ya
que nos permite construir modelos de razonamiento en base a la informaciÃ³n disponible del
entorno de forma similar a como creemos que funcionan los procesos de aprendizaje humanos.
Aunque como muchas otras tÃ©cnicas de Inteligencia Artificial es extremadamente sensible y
dependiente a la forma en la que la informaciÃ³n del entorno es modelada. En el caso del
aprendizaje automÃ¡tico la definiciÃ³n de los datos, tanto a nivel de estructura como a nivel de
suficiente nÃºmero de ejemplos representativos del concepto que se quiere aprender, es muy
importante ya que una mala definiciÃ³n de los atributos de la informaciÃ³n utilizada durante el
proceso de aprendizaje puede producir la extracciÃ³n de conclusiones errÃ³neas o producir
modelos que no generalizando correctamente bien debido a la falta de informaciÃ³n o a la
utilizaciÃ³n de informaciÃ³n sesgada.
Algunos ejemplos de este tipo de problemas pueden observarse en la propia definiciÃ³n de los
diferentes mÃ©todos Aprendizaje Supervisado descritos en este tema. Este tipo de tÃ©cnicas
Â© Structuralia
36Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
necesitan informaciÃ³n precisa (etiquetas) acerca de los diferentes conceptos que representan la
informaciÃ³n que se les suministra para conseguir construir un modelo. Es decir, todos los
ejemplos utilizados para el proceso de aprendizaje deben estÃ¡n etiquetados con el fin de
identificar sus caracterÃ­sticas y relacionarlas con las etiquetas y poder predecir la etiqueta de
futuros ejemplos no etiquetados. Este tipo de proceso presenta dos importantes problemas:
â–ª
El proceso de etiquetado de informaciÃ³n del mundo real de manera lo suficientemente
precisa con el fin de construir modelos muy especÃ­ficos es muy complicada y conlleva un
gran esfuerzo a nivel de recursos fÃ­sicos. Por ejemplo, si quisiÃ©ramos crear un clasificador
para todos los tipos de Ã¡rboles que existen en el planeta tierra deberÃ­amos tomar
informaciÃ³n especÃ­fica de todos los posibles atributos de cada Ã¡rbol, etiquetarlos y
construir un conjunto de entrenamiento lo suficientemente representativo para crear un
modelo que nos permita clasificar cualquier tipo de Ã¡rbol y ademÃ¡s deberÃ­amos tambiÃ©n
crear un conjunto de datos de test con el fin de analizar la eficacia de nuestro modelo.
â–ª
La definiciÃ³n de los atributos que describen las instancias. Cuantos atributos y cuales son
necesarios para describir de forma correcta un concepto, como es posible identificar toda
la informaciÃ³n que es necesario para identificar correctamente cada uno de los distintos
tipos de Ã¡rboles que hay en el planeta tierra. Este es otro de los grandes problemas del
aprendizaje supervisado el cual sigue dependiendo demasiado de la forma en que los
humanos describamos la informaciÃ³n.
Pero tras conocer cÃ³mo funciona el aprendizaje supervisado nos debemos preguntar que si es
posible etiquetar de forma precisa cualquier concepto o si somos capaces de definir de forma
manual todos los atributos necesarios para describir estos conceptos. En el prÃ³ximo tema
describiremos cÃ³mo funcionan los diferentes mÃ©todos de Aprendizaje No Supervisado que son
capaces de construir modelos mediante el anÃ¡lisis de las similitudes entre los atributos de los
conjuntos de instancias sin la necesidad de conocer la etiqueta de cada una de estas instancias.
AdemÃ¡s, describiremos que es el Aprendizaje Profundo y cÃ³mo es capaz de extraer informaciÃ³n
y crear nuevas caracterÃ­sticas de forma automÃ¡tica con el fin de mejorar el proceso de
aprendizaje. Para finalizar aprenderemos que es el Aprendizaje por Refuerzo que intenta simular
la forma en la que los seres vivos aprendemos mediante la utilizaciÃ³n de recompensas que nos
permiten aprender como interactuar de forma fÃ­sica en el entorno.
37
Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
5. REFERENCIAS
[1] M. Minsky. (1967). Computation. Finite and infinite machines. Prentice Hall.
[2] M. Minsky. (1969). Perceptrons: an introduction to computational geometry. MIT Press,
Cambridge, Massachusets.
[3] Schmidhuber, J. (2015). Deep Learning in Neural Networks: An Overview. Neural
Networks. Volumen 61 pp 85-117.
[4] Tom M. Mitchell. (1997) Machine Learning. McGraw-Hill, New York.
[5] Quinlan, J.R. (1986) Induction of decision trees. Machine Learning, Volumen 1(1), pp 81-
106.
[6] Shannon, C.E. (1984) A mathematical theory of communication. Bell System Technical
Journal, volumen 27, pp 379â€“423 y 623â€“656.
[7] Utgoff Paul E. (1989) Incremental Induction of Decision, Trees, Machine Learning, volumen
4, pp 161-186.
[8] Izenman, A.J. (2008) Modern Multivariate Statistical Techniques. Springer.
[9] Duda, R. O., Hart, P. E., and Stork, D. G. (2001). Pattern Classification (2nd ediciÃ³n). John
Wiley.
[10] Arthur S. (1959) Some Studies in Machine Learning Using the Game of Checkers. IBM
Journal of Research and Development. Volumen 3(3). pp 210â€“229.
[11] Copi, I. M.; Cohen, C.; Flage, D. E. (2006). Essentials of Logic (Second edition). Upper
Saddle River, NJ: Pearson Education. ISBN 978-0-13-238034-8.
[12] Sternberg, R. J. (2009). Cognitive Psychology. Belmont, CA: Wadsworth. ISBN 978-0-495-
50629-4.
[13] Watson I. and Marir F. (1994). Case-based reasoning: A review, The Knowledge
Engineering Review, volumen 9(4), pp 327-354.
[14] Dean J. and Ghemawat S. (2004). MapReduce: simplified data processing on large
clusters, Proceedings of the 6th conference on Symposium on operating systems design and
implementation.
[15] Zaharia M., Chowdhury M., Franklin M. J., Shenker S. and Stoica I. (2010). Spark: Cluster
Computing with Working Sets. HotCloud 2010.
Â© Structuralia
38Inteligencia artificial â€“ Aprendizaje automÃ¡tico I
[16] Altman, N. S. (1992). An introduction to kernel and nearest-neighbor nonparametric
regression. The American Statistician. Volumen 46(3).
[17] Ho, Tin Kam (1995). Random Decision Forests. Proceedings of the 3rd International
Conference on Document Analysis and Recognition, Montreal, QC, pp.278â€“282.
[18] Freedman D. A. (2009). Statistical Models: Theory and Practice. Cambridge University
Press.
[19] Haykin S. (1999). Neural Networks: A Comprehensive Foundation. Prentice Hall.
[20] McCulloch, W. and Pitts W. (1943). A Logical Calculus of Ideas Immanent in Nervous
Activity. Bulletin of Mathematical Biophysics. Volumen 5(4). pp 115-133.
3
